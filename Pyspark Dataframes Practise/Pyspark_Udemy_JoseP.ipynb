{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a508779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/pradyut/spark-3.2.3-bin-hadoop3.2-scala2.13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb6d25b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17452f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd894625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/13 08:48:31 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 192.168.78.128 instead (on interface ens33)\n",
      "23/01/13 08:48:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/01/13 08:48:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = SparkSession.builder.appName(\"App1\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbdc14f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = sc.read.json(\"people.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "911d5260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "+----+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d3ab7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88b39e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'name']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d8bd6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------+\n",
      "|summary|               age|   name|\n",
      "+-------+------------------+-------+\n",
      "|  count|                 2|      3|\n",
      "|   mean|              24.5|   null|\n",
      "| stddev|7.7781745930520225|   null|\n",
      "|    min|                19|   Andy|\n",
      "|    max|                30|Michael|\n",
      "+-------+------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "185b78b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describing Schemas \n",
    "from pyspark.sql.types import StructField,IntegerType,StringType,StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cc96e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = [StructField('age',IntegerType(),True),StructField('name',StringType(),True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f84d0447",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_struc = StructType(fields=data_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8bb60e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = sc.read.json('people.json',schema=final_struc)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb09a405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a911dcb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.column.Column"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Working with dataframes\n",
    "type(df['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba2e8da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| age|\n",
      "+----+\n",
      "|null|\n",
      "|  30|\n",
      "|  19|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "769dbd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(age=None, name='Michael'), Row(age=30, name='Andy')]\n",
      "Row(age=None, name='Michael')\n"
     ]
    }
   ],
   "source": [
    "print(df.head(2))\n",
    "print(df.head(2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37348493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------+\n",
      "| age|   name|New_age|\n",
      "+----+-------+-------+\n",
      "|null|Michael|   null|\n",
      "|  30|   Andy|     33|\n",
      "|  19| Justin|     22|\n",
      "+----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('New_age',df['age']+3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "757acbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+\n",
      "|new_col_age|   name|\n",
      "+-----------+-------+\n",
      "|       null|Michael|\n",
      "|         30|   Andy|\n",
      "|         19| Justin|\n",
      "+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed('age','new_col_age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "baeceb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using SQL to work with.\n",
    "df.createOrReplaceTempView('People')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89afb1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sc.sql('select * from People where age > 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a26ac9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "|age|name|\n",
      "+---+----+\n",
      "| 30|Andy|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb3cc33",
   "metadata": {},
   "source": [
    "#Spark Dataframe Basic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e262f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc1 = SparkSession.builder.appName('Basic_Ops1').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "785baad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = sc1.read.csv('appl_stock.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "469ddbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bead70f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+------------------+----------+---------+------------------+\n",
      "|      Date|      Open|      High|               Low|     Close|   Volume|         Adj Close|\n",
      "+----------+----------+----------+------------------+----------+---------+------------------+\n",
      "|2010-01-04|213.429998|214.499996|212.38000099999996|214.009998|123432400|         27.727039|\n",
      "|2010-01-05|214.599998|215.589994|        213.249994|214.379993|150476200|27.774976000000002|\n",
      "|2010-01-06|214.379993|    215.23|        210.750004|210.969995|138040000|27.333178000000004|\n",
      "+----------+----------+----------+------------------+----------+---------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61da53a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date='2010-01-04', Open=213.429998, High=214.499996, Low=212.38000099999996, Close=214.009998, Volume=123432400, Adj Close=27.727039)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d006e650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|              open|\n",
      "+------------------+\n",
      "|        213.429998|\n",
      "|        214.599998|\n",
      "|        214.379993|\n",
      "|            211.75|\n",
      "|        210.299994|\n",
      "|212.79999700000002|\n",
      "|209.18999499999998|\n",
      "|        207.870005|\n",
      "|210.11000299999998|\n",
      "|210.92999500000002|\n",
      "|        208.330002|\n",
      "|        214.910006|\n",
      "|        212.079994|\n",
      "|206.78000600000001|\n",
      "|202.51000200000001|\n",
      "|205.95000100000001|\n",
      "|        206.849995|\n",
      "|        204.930004|\n",
      "|        201.079996|\n",
      "|192.36999699999998|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.filter('close < 500').select('open').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f20c48bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|              open|             close|\n",
      "+------------------+------------------+\n",
      "|        213.429998|        214.009998|\n",
      "|        214.599998|        214.379993|\n",
      "|        214.379993|        210.969995|\n",
      "|            211.75|            210.58|\n",
      "|        210.299994|211.98000499999998|\n",
      "|212.79999700000002|210.11000299999998|\n",
      "|209.18999499999998|        207.720001|\n",
      "|        207.870005|        210.650002|\n",
      "|210.11000299999998|            209.43|\n",
      "|210.92999500000002|            205.93|\n",
      "|        208.330002|        215.039995|\n",
      "|        214.910006|            211.73|\n",
      "|        212.079994|        208.069996|\n",
      "|206.78000600000001|            197.75|\n",
      "|202.51000200000001|        203.070002|\n",
      "|205.95000100000001|        205.940001|\n",
      "|        206.849995|        207.880005|\n",
      "|        204.930004|        199.289995|\n",
      "|        201.079996|        192.060003|\n",
      "|192.36999699999998|        194.729998|\n",
      "+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.filter(df1['close']<500).select(['open','close']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "55e57aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+----------+----------+----------+---------+------------------+\n",
      "|      Date|              Open|      High|       Low|     Close|   Volume|         Adj Close|\n",
      "+----------+------------------+----------+----------+----------+---------+------------------+\n",
      "|2010-01-22|206.78000600000001|207.499996|    197.16|    197.75|220441900|         25.620401|\n",
      "|2010-01-28|        204.930004|205.500004|198.699995|199.289995|293375600|25.819922000000002|\n",
      "|2010-01-29|        201.079996|202.199995|190.250002|192.060003|311488100|         24.883208|\n",
      "+----------+------------------+----------+----------+----------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.filter((df1['close'] < 200) & (df1['open']>200)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b02643c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|      Date|              Open|              High|               Low|             Close|   Volume|         Adj Close|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|2010-02-01|192.36999699999998|             196.0|191.29999899999999|        194.729998|187469100|         25.229131|\n",
      "|2010-02-02|        195.909998|        196.319994|193.37999299999998|        195.859997|174585600|25.375532999999997|\n",
      "|2010-02-03|        195.169994|        200.200003|        194.420004|        199.229994|153832000|25.812148999999998|\n",
      "|2010-02-04|        196.730003|        198.370001|        191.570005|        192.050003|189413000|         24.881912|\n",
      "|2010-02-05|192.63000300000002|             196.0|        190.850002|        195.460001|212576700|25.323710000000002|\n",
      "|2010-02-08|        195.690006|197.88000300000002|        193.999994|194.11999699999998|119567700|           25.1501|\n",
      "|2010-02-09|        196.419996|        197.499994|        194.749998|196.19000400000002|158221700|         25.418289|\n",
      "|2010-02-10|        195.889997|             196.6|            194.26|195.12000700000002| 92590400|          25.27966|\n",
      "|2010-02-11|        194.880001|        199.750006|194.05999599999998|        198.669994|137586400|         25.739595|\n",
      "|2010-02-23|        199.999998|        201.330002|        195.709993|        197.059998|143773700|         25.531005|\n",
      "|2014-06-09|         92.699997|         93.879997|             91.75|         93.699997| 75415000|         88.906324|\n",
      "|2014-06-10|         94.730003|         95.050003|             93.57|             94.25| 62777000|         89.428189|\n",
      "|2014-06-11|         94.129997|         94.760002|         93.470001|         93.860001| 45681000|         89.058142|\n",
      "|2014-06-12|         94.040001|         94.120003|         91.900002|         92.290001| 54749000|         87.568463|\n",
      "|2014-06-13|         92.199997|         92.440002|         90.879997|         91.279999| 54525000|         86.610132|\n",
      "|2014-06-16|         91.510002|             92.75|         91.449997|         92.199997| 35561000|         87.483064|\n",
      "|2014-06-17|         92.309998|         92.699997|         91.800003| 92.08000200000001| 29726000| 87.36920699999999|\n",
      "|2014-06-18|         92.269997|         92.290001|         91.349998|             92.18| 33514000|          87.46409|\n",
      "|2014-06-19|         92.290001|         92.300003|         91.339996|         91.860001| 35528000|         87.160461|\n",
      "|2014-06-20|         91.849998|         92.550003|         90.900002|         90.910004|100898000|         86.259066|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.filter((df1['close'] < 200) & ~(df1['open']>200)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "417de265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting result as Rows - As list\n",
    "rows = df1.filter(df1['Low']>100).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b6d1703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get a particular Row\n",
    "row = rows[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f7512aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': '2010-01-05',\n",
       " 'Open': 214.599998,\n",
       " 'High': 215.589994,\n",
       " 'Low': 213.249994,\n",
       " 'Close': 214.379993,\n",
       " 'Volume': 150476200,\n",
       " 'Adj Close': 27.774976000000002}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.asDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6963f28",
   "metadata": {},
   "source": [
    "## Group By and Aggregate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2ac091b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc3 = SparkSession.builder.appName('Basic_App2').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "76f45303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = sc3.read.csv('sales_info.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "46e6cb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   GOOG|Charlie|120.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "|     FB|   Carl|870.0|\n",
      "|     FB|  Sarah|350.0|\n",
      "|   APPL|   John|250.0|\n",
      "|   APPL|  Linda|130.0|\n",
      "|   APPL|   Mike|750.0|\n",
      "|   APPL|  Chris|350.0|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "485bc504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Person: string (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8871e765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.group.GroupedData at 0x7ff458f594f0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.groupBy('Company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5d05f007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|Company|       avg(Sales)|\n",
      "+-------+-----------------+\n",
      "|   APPL|            370.0|\n",
      "|   GOOG|            220.0|\n",
      "|     FB|            610.0|\n",
      "|   MSFT|322.3333333333333|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.groupBy('Company').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2a408d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|max(Sales)|\n",
      "+----------+\n",
      "|     870.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.agg({'Sales':'max'}).show() #Aggregate function takes args as dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f8e3971a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|Company|Sales_Count|\n",
      "+-------+-----------+\n",
      "|   APPL|          4|\n",
      "|   GOOG|          3|\n",
      "|     FB|          2|\n",
      "|   MSFT|          3|\n",
      "+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.groupBy('Company').agg({'Sales':'count'}).withColumnRenamed('count(Sales)','Sales_Count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "92e59ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "06eadf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|        Avg_Sales|\n",
      "+-----------------+\n",
      "|360.5833333333333|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.select(avg('Sales').alias('Avg_Sales')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9adb4259",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_std = df3.select(stddev('Sales').alias('std'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "adcd140c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|std_formatted|\n",
      "+-------------+\n",
      "|       250.09|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_std.select(format_number('std',2).alias('std_formatted')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7aa3f94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|Charlie|120.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "|   APPL|  Linda|130.0|\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "|   APPL|   John|250.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|     FB|  Sarah|350.0|\n",
      "|   APPL|  Chris|350.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|   APPL|   Mike|750.0|\n",
      "|     FB|   Carl|870.0|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.orderBy('Sales').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e6153a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|     FB|   Carl|870.0|\n",
      "|   APPL|   Mike|750.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|     FB|  Sarah|350.0|\n",
      "|   APPL|  Chris|350.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|   APPL|   John|250.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   APPL|  Linda|130.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "|   GOOG|Charlie|120.0|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.orderBy(col('Sales').desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8010c3fa",
   "metadata": {},
   "source": [
    "## Handling missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "217e17f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc4 = SparkSession.builder.appName('Fix_Misses').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "58d0abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = sc4.read.csv('ContainsNull.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a369544d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| null|\n",
      "|emp2| null| null|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c43059e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "575697cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| null|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.na.drop(thresh=2).show() #Giving threshold not null counts to consider it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8462ba98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| null|\n",
      "|emp2| null| null|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.na.drop(how='all').show() #How to apply na Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "19059294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.na.drop(subset=['Sales']).show() #na only on Sales Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "21adc012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| null|\n",
      "|emp2|  XXX| null|\n",
      "|emp3|  XXX|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.na.fill(\"XXX\",subset=[\"Name\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e6412b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John|400.5|\n",
      "|emp2| null|400.5|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_sale = df4.select(mean('Sales')).collect()[0][0]\n",
    "df4.na.fill(mean_sale,['Sales','Name']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e177feaf",
   "metadata": {},
   "source": [
    "## Dates and Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b21c77ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"dates\").getOrCreate()\n",
    "df_dates = spark.read.csv(\"appl_stock.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa99ac44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date='2010-01-04', Open=213.429998, High=214.499996, Low=212.38000099999996, Close=214.009998, Volume=123432400, Adj Close=27.727039)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dates.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4969a677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|      Date|      Open|\n",
      "+----------+----------+\n",
      "|2010-01-04|213.429998|\n",
      "|2010-01-05|214.599998|\n",
      "+----------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dates.select('Date','Open').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0b545f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b4b96ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|dayofmonth(Date)|\n",
      "+----------------+\n",
      "|               4|\n",
      "|               5|\n",
      "|               6|\n",
      "|               7|\n",
      "|               8|\n",
      "|              11|\n",
      "|              12|\n",
      "|              13|\n",
      "|              14|\n",
      "|              15|\n",
      "|              19|\n",
      "|              20|\n",
      "|              21|\n",
      "|              22|\n",
      "|              25|\n",
      "|              26|\n",
      "|              27|\n",
      "|              28|\n",
      "|              29|\n",
      "|               1|\n",
      "+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dates.select(dayofmonth(df_dates['Date'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97e60f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|month(Date)|\n",
      "+-----------+\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dates.select(month(df_dates['Date'])).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1e215d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = df_dates.withColumn('Year',year(df_dates['Date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e55b26fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdf.printSchema()\n",
    "newdf2 = newdf.groupBy('Year').mean().select('Year','avg(Close)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e14a32eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------+\n",
      "|Year|Average Closing Price|\n",
      "+----+---------------------+\n",
      "|2016|               104.60|\n",
      "|2015|               120.04|\n",
      "|2014|               295.40|\n",
      "|2013|               472.63|\n",
      "|2012|               576.05|\n",
      "|2011|               364.00|\n",
      "|2010|               259.84|\n",
      "+----+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf2.select('Year',format_number('avg(Close)',2).alias('Average Closing Price')).orderBy(newdf2['Year'].desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834d98ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
